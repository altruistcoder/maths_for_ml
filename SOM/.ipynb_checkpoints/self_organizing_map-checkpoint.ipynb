{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Organizing Feature Map "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to build and understand the properties of Kohonen Self-Organizing Feature Maps, an unsupervised learning technique for representing high dimensional data in much lower dimensional spaces, while maintaining the topological relationships within the training set.\n",
    "\n",
    "We will begin first by building a model that can map colors in RGB to a 2 dimensional representation. Next, we will take the same model and apply it to a more advanced problem of learning from the MNIST dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing necessary Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An SOM is a lattice made up of n by n nodes. From an initial random distribution of weights, the weights are adjusted over training to classify the input data more effectively, until it converges to a steady representation of different zones (equivalent to classes). Given an input data, the SOM can classify based as nodes in zone with similar weight vectors will be simulated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning Algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For N Iterations:\n",
    "\n",
    "1. Initialise weights of each node in lattice randomly\n",
    "2. Select a vector from training data to compare with the lattice.\n",
    "3. Choose Best Matching Unit (BMU) from lattice, by computing the most similar node to vector.\n",
    "4. Compute the radius of BMU's neighbourhood. This value decreases each time-step.\n",
    "5. Adjust each node within the BMU's neighbourhood to make them more similar to the input vector. Closer nodes are adusted more.\n",
    "6. Repeat Step 2 to 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out http://www.ai-junkie.com/ann/som/som3.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOM:\n",
    "    def __init__(self, x_size, y_size, dimen, num_iter, t_step):\n",
    "        # init weights to 0 < w < 256\n",
    "        self.weights = np.random.randint(256, size=(x_size, y_size, dimen))\\\n",
    "                            .astype('float64')\n",
    "        self.num_iter = num_iter\n",
    "        self.map_radius = max(self.weights.shape)/2 # sigma_0\n",
    "        self.t_const = self.num_iter/math.log(self.map_radius) # lambda\n",
    "        self.t_step = t_step\n",
    "        \n",
    "    def get_bmu(self, vector):\n",
    "        # calculate euclidean dist btw weight matrix and vector\n",
    "        distance = np.sum((self.weights - vector) ** 2, 2)\n",
    "        min_idx = distance.argmin()\n",
    "        return np.unravel_index(min_idx, distance.shape)\n",
    "        \n",
    "    def get_bmu_dist(self, vector):\n",
    "        # initialize array where values are its index\n",
    "        x, y, rgb = self.weights.shape\n",
    "        xi = np.arange(x).reshape(x, 1).repeat(y, 1)\n",
    "        yi = np.arange(y).reshape(1, y).repeat(x, 0)\n",
    "        # returns matrix of distance of each index in 2D from BMU\n",
    "        return np.sum((np.dstack((xi, yi)) - np.array(self.get_bmu(vector))) ** 2, 2)\n",
    "\n",
    "    def get_nbhood_radius(self, iter_count):\n",
    "        return self.map_radius * np.exp(-iter_count/self.t_const)\n",
    "        \n",
    "    def teach_row(self, vector, i):\n",
    "        nbhood_radius = self.get_nbhood_radius(i)\n",
    "        bmu_dist = self.get_bmu_dist(vector).astype('float64')\n",
    "        \n",
    "        # exponential decaying learning rate\n",
    "        lr = 0.1 * np.exp(-i/self.num_iter) \n",
    "        \n",
    "        # influence\n",
    "        theta = np.exp(-(bmu_dist)/ (2 * nbhood_radius ** 2))\n",
    "        return np.expand_dims(theta, 2) * (vector - self.weights)\n",
    "        \n",
    "    def teach(self, t_set):\n",
    "        for i in range(self.num_iter):\n",
    "            if i % 10 == 0:\n",
    "                print(\"Training Iteration: \", i)\n",
    "            for j in range(len(t_set)):\n",
    "                self.weights += self.teach_row(t_set[j], i)\n",
    "        \n",
    "    def show(self):\n",
    "        im = Image.fromarray(self.weights.astype('uint8'), mode='RGB')\n",
    "        im.format = 'JPG'\n",
    "        im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration:  0\n",
      "Training Iteration:  10\n",
      "Training Iteration:  20\n",
      "Training Iteration:  30\n",
      "Training Iteration:  40\n",
      "Training Iteration:  50\n",
      "Training Iteration:  60\n",
      "Training Iteration:  70\n",
      "Training Iteration:  80\n",
      "Training Iteration:  90\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "map_w = 200\n",
    "map_h = 200\n",
    "data_dim = 3\n",
    "epochs = 100\n",
    "t_step = 1\n",
    "\n",
    "# Initialize random RGB dataset\n",
    "train_set = np.random.randint(256, size=(15,3))\n",
    "\n",
    "# Defining map\n",
    "s = SOM(map_w, map_h, data_dim, epochs, t_step)\n",
    "\n",
    "# Start Training\n",
    "s.teach(train_set)\n",
    "s.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training on MNIST Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/darkghost/anaconda3/envs/MLenv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/darkghost/anaconda3/envs/MLenv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /home/darkghost/anaconda3/envs/MLenv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /home/darkghost/anaconda3/envs/MLenv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/darkghost/anaconda3/envs/MLenv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/darkghost/anaconda3/envs/MLenv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using first 10000 images for training\n",
    "train_data = mnist.train.images[:10000,:]\n",
    "\n",
    "# Converting normalized data to values between 0 and 256\n",
    "train_data = train_data * 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration:  0\n",
      "Training Iteration:  10\n",
      "Training Iteration:  20\n",
      "Training Iteration:  30\n",
      "Training Iteration:  40\n",
      "Training Iteration:  50\n",
      "Training Iteration:  60\n",
      "Training Iteration:  70\n",
      "Training Iteration:  80\n",
      "Training Iteration:  90\n"
     ]
    }
   ],
   "source": [
    "map_w = 20\n",
    "map_h = 20\n",
    "data_dim = 784\n",
    "epochs = 100\n",
    "t_step = 1\n",
    "\n",
    "# Defining map\n",
    "mnist_map = SOM(map_w, map_h, data_dim,epochs, t_step)\n",
    "\n",
    "#Start training\n",
    "mnist_map.teach(train_data)\n",
    "\n",
    "# Converting 3D SOM to 2D image\n",
    "map_matrix = np.zeros((560,560))\n",
    "for i in range(map_w):\n",
    "    for j in range(map_h):\n",
    "        # Reshaping 768 weight vector to 28x28 matrix\n",
    "        reshaped_weights = mnist_map.weights[i][j].reshape((28, 28))\n",
    "        # Assigning matrix to respective position of node in lattice\n",
    "        map_matrix[i*28:i*28+28, j*28:((j*28)+28)] = reshaped_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing Image\n",
    "map_img = Image.fromarray(map_matrix.astype('uint8'))\n",
    "map_img.format = 'JPG'\n",
    "map_img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"mnistpic.jpeg\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLenv]",
   "language": "python",
   "name": "conda-env-MLenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
